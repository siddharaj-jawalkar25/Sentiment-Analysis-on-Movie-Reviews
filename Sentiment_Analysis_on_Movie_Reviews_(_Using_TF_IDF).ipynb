{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis on Movie Reviews ( Using TF-IDF).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the Dataset"
      ],
      "metadata": {
        "id": "asw4TZgXIfFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Data"
      ],
      "metadata": {
        "id": "diKc_9hU91iS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2Ac--dHr9kSP"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "dataset = pd.read_csv('IMDB Dataset.csv',engine = 'python', error_bad_lines=False)\n",
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH5kBlR591SE",
        "outputId": "fe775200-a686-40e1-fda2-f3b713cdfc31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming Documents into Feature Vectors"
      ],
      "metadata": {
        "id": "AH6PPzEpC19e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming Documents into Feature Vectors\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count = CountVectorizer()\n",
        "docs = ([\n",
        "         'The dog is running',\n",
        "         'I like chocolates beacause it is sweet',\n",
        "         'The dog is running and chocolate is sweet, and two and two is four'\n",
        "])\n",
        "bag = count.fit_transform(docs)\n",
        "print(count.vocabulary_)\n",
        "print(bag.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKOQ5XY4-b5C",
        "outputId": "57b5a030-b876-48cf-b7c9-73160dfd5e3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 11, 'dog': 4, 'is': 6, 'running': 9, 'like': 8, 'chocolates': 3, 'beacause': 1, 'it': 7, 'sweet': 10, 'and': 0, 'chocolate': 2, 'two': 12, 'four': 5}\n",
            "[[0 0 0 0 1 0 1 0 0 1 0 1 0]\n",
            " [0 1 0 1 0 0 1 1 1 0 1 0 0]\n",
            " [3 0 1 0 1 1 3 0 0 1 1 1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Relevancy using TF-IDF"
      ],
      "metadata": {
        "id": "Nr4BQgYlFKuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Relevancy using TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "np.set_printoptions(precision=2)\n",
        "tfidf = TfidfTransformer(use_idf = True, norm='l2', smooth_idf = True)\n",
        "print(tfidf.fit_transform(bag).toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0jDCHZJE9vS",
        "outputId": "44730cbc-f09b-48cb-8855-e4d36eec2c5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.   0.   0.   0.53 0.   0.41 0.   0.   0.53 0.   0.53 0.  ]\n",
            " [0.   0.45 0.   0.45 0.   0.   0.27 0.45 0.45 0.   0.34 0.   0.  ]\n",
            " [0.66 0.   0.22 0.   0.17 0.22 0.39 0.   0.   0.17 0.17 0.17 0.44]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning\n"
      ],
      "metadata": {
        "id": "x53eaoPrIm_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning - removing tags , replacing all the emoticons at the end of line\n",
        "import re\n",
        "def preprocessor(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = re.sub('[\\W]+', ' ', text.lower()) + ''.join(emoticons).replace('-', '')\n",
        "  return text\n",
        "preprocessor(\"This is a :) test :-( !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h48Uu6TKHMiO",
        "outputId": "32498e0e-f3ab-4c43-9728-1d62e0d91ad1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is a test :):('"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization of Documents"
      ],
      "metadata": {
        "id": "4VyH7tIwQuoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization of Document\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "def tokenizer(text):\n",
        "  return text.split()\n",
        "tokenizer('Running like running thus they run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyuhlXqoQZnn",
        "outputId": "2ea034f9-b723-45a9-b9f4-cebd6f7f1deb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Running', 'like', 'running', 'thus', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization of Document and Steaming\n",
        "def tokenizer_stemmer(text):\n",
        "  return[porter.stem(word) for word in text.split()]\n",
        "tokenizer_stemmer('Running like running thus they run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu31chftRF6N",
        "outputId": "adc9c5ad-101b-4725-9852-8391691faaca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['run', 'like', 'run', 'thu', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Text Data into TF-IDF Vectors"
      ],
      "metadata": {
        "id": "SRJ25wlcRj-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Text Data into TF-IDF Vectors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                         lowercase=True,\n",
        "                         preprocessor=preprocessor,  # applied preprocessor in Data Cleaning\n",
        "                         tokenizer=tokenizer_stemmer,\n",
        "                         use_idf=True,\n",
        "                         norm='l2',\n",
        "                         smooth_idf=True)\n",
        "y = dataset.sentiment.values\n",
        "X = tfidf.fit_transform(dataset.review)"
      ],
      "metadata": {
        "id": "3c_u7Z7JRiJe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document Classification using Logistic Regression"
      ],
      "metadata": {
        "id": "atPNsC0wV08q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Logistic Regression model on Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state =1, shuffle=False)\n",
        "clf = LogisticRegressionCV(cv=5, \n",
        "                           scoring = 'accuracy',\n",
        "                           random_state = 0,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 3,\n",
        "                           max_iter = 300).fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQItX9tFTQgO",
        "outputId": "6cdd9108-d998-4c64-fe4f-79f65c8ab021"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.9min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "uOCwlwpQW1VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyQvi86JWrYf",
        "outputId": "096f28f5-419f-4388-ede7-d47ab1946262"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89476"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "y87sGgOdemSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the result for X_test\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "Q8Ok3GqjXDr9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To evaluate the performance of a classification model create confussion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9kJ74vxeeR7",
        "outputId": "5646120b-7621-42bb-c7d6-323f668426a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11046  1428]\n",
            " [ 1203 11323]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89476"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nE0eXIhoejua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}